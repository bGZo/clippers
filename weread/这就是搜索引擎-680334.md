---
doc_type: weread-highlights-reviews
bookId: "680334"
reviewCount: 0
noteCount: 3
author:
  - 张俊林
  - 电子工业出版社
cover: https://cdn.weread.qq.com/weread/cover/30/YueWen_680334/t7_YueWen_680334.jpg
readingStatus: 在读
progress: "-1"
totalReadDay: 3
readingTime: 0小时0分钟
readingDate: 2022-06-04
title: 这就是搜索引擎
published: 2012-01-01 00:00:00
isbn: 9787121148651
tags:
  - weread/计算机-理论知识
type: weread-notes
weread: https://weread.qq.com/web/reader/a28325105a618ea287e580a

---


## 封面

## 版权信息

## 前言

> [!NOTE] 
> 倒排索引、检索模型和爬虫等常见内容，也要详细讲解链接分析、网页反作弊、用户搜索意图分析、云存储及网页去重，甚至是搜索引擎缓存等内容，这些都是一个完整搜索引擎的有机构成部分
> 
> 2022-06-04 00:14:10 ^680334-3-1064-1149

## 第1章 搜索引擎及其技术架构

### 1.1 搜索引擎为何重要

### 1.2 搜索引擎技术发展史

### 1.3 搜索引擎的3个目标

### 1.4 搜索引擎的3个核心问题

### 1.5 搜索引擎的技术架构

## 第2章 网络爬虫

### 2.1 通用爬虫框架

### 2.2 优秀爬虫的特性

### 2.3 爬虫质量的评价标准

### 2.4 抓取策略

### 2.5 网页更新策略

### 2.6 暗网抓取（Deep Web Crawling）

### 2.7 分布式爬虫

## 第3章 搜索引擎索引

### 3.1 索引基础

### 3.2 单词词典

### 3.3 倒排列表（Posting List）

### 3.4 建立索引

### 3.5 动态索引

### 3.6 索引更新策略

### 3.7 查询处理

### 3.8 多字段索引

### 3.9 短语查询

### 3.10 分布式索引（Parallel Indexing）

## 第4章 索引压缩

### 4.1 词典压缩

### 4.2 倒排列表压缩算法

### 4.3 文档编号重排序（DocID Reordering）

### 4.4 静态索引裁剪（Static Index Pruning）

## 第5章 检索模型与搜索排序

### 5.1 布尔模型（Boolean Model）

### 5.2 向量空间模型（Vector Space Model）

### 5.3 概率检索模型

### 5.4 语言模型方法

### 5.5 机器学习排序（Learning to Rank）

### 5.6 检索质量评价标准

## 第6章 链接分析

### 6.1 Web图

### 6.2 两个概念模型及算法之间的关系

### 6.3 PageRank算法

### 6.4 HITS算法（Hypertext Induced Topic Selection）

### 6.5 SALSA算法

### 6.6 主题敏感PageRank（Topic Sensitive PageRank）

### 6.7 Hilltop算法

### 6.8 其他改进算法

## 第7章 云存储与云计算

### 7.1 云存储与云计算概述

### 7.2 Google文件系统（GFS）

### 7.3 Chubby锁服务

### 7.4 BigTable

### 7.5 Megastore系统

### 7.6 Map/Reduce云计算模型

### 7.7 咖啡因系统——Percolator

### 7.8 Pregel图计算模型

### 7.9 Dynamo云存储系统

### 7.10 PNUTS云存储系统

### 7.11 HayStack存储系统

## 第8章 网页反作弊

### 8.1 内容作弊

### 8.2 链接作弊

### 8.3 页面隐藏作弊

### 8.4 Web2.0作弊方法

> [!NOTE] 
> TrackBack机制是博客作者之间相互引用通知的机制。比如博客A发表了一篇博文，之后博客B看到这篇文章后，发表了一篇主题类似的博文，并在文中使用链接引用博客A的博文，如果两者的博客系统都支持TrackBak协议，则博客系统会自动在博客A的文章后增加指向博客B新博文的链接。博客发布系统支持TrackBack协议的初衷是引导博客群体形成讨论氛围，不过很多作弊者利用这一点，使用自动TrackBack群发软件，向大量博文发出TrackBack链接，这样就增加了作弊页面被访问的机会
> 
> 2022-06-15 09:47:15 ^680334-66-934-1173

> [!NOTE] 
> 作弊者大量关注他人微博，很多人出于礼貌也会将其作为关注者（互粉行为），在吸引到一定量的关注者后，作弊者会发布广告信息，这些广告信息就会出现在其关注者的阅读列表中，以此达到营销的目的。
> 
> 2022-06-15 09:47:54 ^680334-66-1882-1973

### 8.5 反作弊技术的整体思路

### 8.6 通用链接反作弊方法

### 8.7 专用链接反作弊技术

### 8.8 识别内容作弊

### 8.9 反隐藏作弊

### 8.10 搜索引擎反作弊综合框架

## 第9章 用户查询意图分析

### 9.1 搜索行为及其意图

### 9.2 搜索日志挖掘

### 9.3 相关搜索

### 9.4 查询纠错

## 第10章 网页去重

### 10.1 通用去重算法框架

### 10.2 Shingling算法

### 10.3 I-Match算法

### 10.4 SimHash算法

### 10.5 SpotSig算法

## 第11章 搜索引擎缓存机制

### 11.1 搜索引擎缓存系统架构

### 11.2 缓存对象

### 11.3 缓存结构

### 11.4 缓存淘汰策略（Evict Policy）

### 11.5 缓存更新策略（Refresh Policy）

## 第12章 搜索引擎发展趋势

### 12.1 个性化搜索

### 12.2 社会化搜索

### 12.3 实时搜索

### 12.4 移动搜索

### 12.5 地理位置感知搜索

### 12.6 跨语言搜索

### 12.7 多媒体搜索

### 12.8 情境搜索

