---
doc_type: weread-highlights-reviews
bookId: "928559"
reviewCount: 0
noteCount: 13
author:
  - 唐松 陈智铨
  - 机械工业出版社
cover: https://cdn.weread.qq.com/weread/cover/30/YueWen_928559/t7_YueWen_928559.jpg
readingStatus: 读过
progress: 20%
totalReadDay: 2
readingTime: 0小时23分钟
readingDate: 2021-04-25
title: Python网络爬虫从入门到实践
published: 2017-09-01 00:00:00
isbn: 9787111578413
tags:
  - weread/计算机-编程设计
type: weread-notes
weread: https://weread.qq.com/web/reader/37132a705e2b2f37196c138

---


## 封面

## 版权信息

## 推荐序一

## 推荐序二

## 前言一

## 前言二

## 第1章 网络爬虫入门

### 1.1 为什么要学网络爬虫

### 1.2 网络爬虫是否合法

### 1.3 网络爬虫的基本议题

## 第2章 编写第一个网络爬虫

### 2.1 搭建Python平台

> [!NOTE] 
> bs4
> 
> 2021-04-25 10:59:41 ^928559-12-2844-2847

> [!NOTE] 
> BeautifulSoup
> 
> 2021-04-25 10:59:46 ^928559-12-2856-2869

### 2.2 Python使用入门

> [!NOTE] 
> 1．封装
> 
> 2021-04-27 08:30:59 ^928559-13-8118-8122

> [!NOTE] 
> init_
> 
> 2021-04-27 08:31:41 ^928559-13-8507-8512

> [!NOTE] 
> 调用被封装的内容时有两种方式：通过对象直接调用和通过self间接调用。
> 
> 2021-04-27 08:32:26 ^928559-13-9030-9065

> [!NOTE] 
> 对于继承来说，其实就是将多个类共有的方法提取到父类中，子类继承父类中的方法即可，不必一一实现每个方法。
> 
> 2021-04-27 08:33:53 ^928559-13-12619-12670

### 2.3 编写第一个简单的爬虫

> [!NOTE] 
> soup.find("h1", class_="post-title").a.text.strip()提取该博文的标题
> 
> 2021-04-27 08:35:18 ^928559-14-3921-3980

### 2.4 Python实践：基础巩固

> [!NOTE] 
> 请不要复制、粘贴代码。复制、粘贴代码除了可以让你在短时间内完成任务之外，没有任何好处。只有通过亲自输入代码，并不断重复、不断加快速度，才会提升你的编程能力和编程效率。否则给你一张白纸，你会什么代码都写不出。
> 
> 2021-04-27 08:36:34 ^928559-15-1191-1294

> [!NOTE] 
> 这是因为对象有两种，即可更改（mutable）与不可更改（immutable）对象。在Python中，strings、tuples和numbers是不可更改对象，而list、dict等是可更改对象。
> 
> 2021-04-27 08:37:25 ^928559-15-6998-7097

## 第3章 静态网页抓取

### 3.1 安装Requests

### 3.2 获取响应内容

> [!NOTE] 
> s.get
> 
> 2021-04-27 08:40:59 ^928559-18-570-575

### 3.3 定制Requests

> [!NOTE] 
> Requests
> 
> 2021-04-27 08:42:41 ^928559-19-477-485

> [!NOTE] 
> 在Requests中，你可以直接把这些参数保存在字典中，用params构建至URL中
> 
> 2021-04-27 08:43:09 ^928559-19-842-884

> [!NOTE] 
> 了关于请求、响应或其他发送实体的信息
> 
> 2021-04-27 08:45:46 ^928559-19-2060-2078

### 3.4 Requests爬虫实践：TOP250电影数据

## 第4章 动态网页抓取

### 4.1 动态抓取的实例

### 4.2 解析真实地址抓取

### 4.3 通过Selenium模拟浏览器抓取

### 4.4 Selenium爬虫实践：深圳短租数据

## 第5章 解析网页

### 5.1 使用正则表达式解析网页

### 5.2 使用BeautifulSoup解析网页

### 5.3 使用lxml解析网页

### 5.4 总结

### 5.5 BeautifulSoup爬虫实践：房屋价格数据

## 第6章 数据存储

### 6.1 基本存储：存储至TXT或CSV

### 6.2 存储至MySQL数据库

### 6.3 存储至MongoDB数据库

### 6.4 总结

### 6.5 MongoDB爬虫实践：虎扑论坛

## 第7章 提升爬虫的速度

### 7.1 并发和并行，同步和异步

### 7.2 多线程爬虫

### 7.3 多进程爬虫

### 7.4 多协程爬虫

### 7.5 总结

## 第8章 反爬虫问题

### 8.1 为什么会被反爬虫

### 8.2 反爬虫的方式有哪些

### 8.3 如何“反反爬虫”

### 8.4 总结

## 第9章 解决中文乱码

### 9.1 什么是字符编码

### 9.2 Python的字符编码

### 9.3 解决中文编码问题

### 9.4 总结

## 第10章 登录与验证码处理

### 10.1 处理登录表单

### 10.2 验证码的处理

### 10.3 总结

## 第11章 服务器采集

### 11.1 为什么使用服务器采集

### 11.2 使用动态IP拨号服务器

### 11.3 使用Tor代理服务器

## 第12章 分布式爬虫

### 12.1 安装Redis

### 12.2 修改Redis配置

### 12.3 Redis分布式爬虫实践

### 12.4 总结

## 第13章 爬虫实践一：维基百科

### 13.1 项目描述

### 13.2 网站分析

### 13.3 项目实施：深度优先的递归爬虫

### 13.4 项目进阶：广度优先的多线程爬虫

### 13.5 总结

## 第14章 爬虫实践二：知乎Live

### 14.1 项目描述

### 14.2 网站分析

### 14.3 项目实施

### 14.4 总结

## 第15章 爬虫实践三：百度地图API

### 15.1 项目描述

### 15.2 获取API秘钥

### 15.3 项目实施

### 15.4 总结

## 第16章 爬虫实践四：餐厅点评

### 16.1 项目描述

### 16.2 网站分析

### 16.3 项目实施

### 16.4 总结

