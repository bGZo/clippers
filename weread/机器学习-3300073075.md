---
doc_type: weread-highlights-reviews
bookId: "3300073075"
reviewCount: 0
noteCount: 5
author:
  - 周志华
  - 清华大学出版社
cover: https://cdn.weread.qq.com/weread/cover/47/cpplatform_8sywey1dxsqhekc8xqt8r4/t7_cpplatform_8sywey1dxsqhekc8xqt8r41696907706.jpg
readingStatus: 在读
progress: "-1"
totalReadDay: 1
readingTime: 0小时0分钟
readingDate: 2024-04-23
title: 机器学习
published: 2016-01-01 00:00:00
isbn: 9787302423287
tags:
  - weread/计算机-人工智能
type: weread-notes
weread: https://weread.qq.com/web/reader/4f1323a0813ab830bg015271

---


## 封面

## 版权信息

## 序言

> [!NOTE] 
> 在人工智能发展早期，机器学习的技术内涵几乎全部是符号学习。可是从二十世纪九十年代开始，统计机器学习犹如一匹黑马横空出世，迅速压倒并取代了符号学习的地位。
> 
> 2024-04-23 07:16:40 ^3300073075-3-921-997

> [!NOTE] 
> 但它们真的代表了机器学习的新的方向吗？包括本书作者周志华教授在内的一些学者认为：深度学习掀起的热潮也许大过它本身真正的贡献，在理论和技术上并没有太多的创新，只不过是由于硬件技术的革命，计算机的速度大大提高了，使得人们有可能采用原来复杂度很高的算法，从而得到比过去更精细的结果
> 
> 2024-04-23 07:17:48 ^3300073075-3-2252-2389

> [!NOTE] 
> 机器学习研究出现以来，我们看到的主要是从符号方法到统计方法的演变，用到的数学主要是概率统计。
> 
> 2024-04-23 07:22:58 ^3300073075-3-2692-2738

> [!NOTE] 
> 符号机器学习时代主要以离散方法处理问题，统计机器学习时代主要以连续方法处理问题。
> 
> 2024-04-23 07:19:04 ^3300073075-3-3187-3227

> [!NOTE] 
> 大数据时代的出现，有没有给机器学习带来本质性的影响？理论上讲，似乎“大数据”给统计机器学习提供了更多的机遇，因为海量的数据更加需要统计、抽样的方法。
> 
> 2024-04-23 07:22:47 ^3300073075-3-3435-3509

## 前言

## 如何使用本书——写在第十次印刷之际

## 主要符号表

## 第1章 绪论

### 1.1 引言

### 1.2 基本术语

### 1.3 假设空间

### 1.4 归纳偏好

### 1.5 发展历程

### 1.6 应用现状

### 1.7 阅读材料

### 习题

### 参考文献

### 休息一会儿

## 第2章 模型评估与选择

### 2.1 经验误差与过拟合

### 2.2 评估方法

### 2.3 性能度量

### 2.4 比较检验

### 2.5 偏差与方差

### 2.6 阅读材料

### 习题

### 参考文献

### 休息一会儿

## 第3章 线性模型

### 3.1 基本形式

### 3.2 线性回归

### 3.3 对数几率回归

### 3.4 线性判别分析

### 3.5 多分类学习

### 3.6 类别不平衡问题

### 3.7 阅读材料

### 习题

### 参考文献

### 休息一会儿

## 第4章 决策树

### 4.1 基本流程

### 4.2 划分选择

### 4.3 剪枝处理

### 4.4 连续与缺失值

### 4.5 多变量决策树

### 4.6 阅读材料

### 习题

### 参考文献

### 休息一会儿

## 第5章 神经网络

### 5.1 神经元模型

### 5.2 感知机与多层网络

### 5.3 误差逆传播算法

### 5.4 全局最小与局部极小

### 5.5 其他常见神经网络

### 5.6 深度学习

### 5.7 阅读材料

### 习题

### 参考文献

### 休息一会儿

## 第6章 支持向量机

### 6.1 间隔与支持向量

### 6.2 对偶问题

### 6.3 核函数

### 6.4 软间隔与正则化

### 6.5 支持向量回归

### 6.6 核方法

### 6.7 阅读材料

### 习题

### 参考文献

### 休息一会儿

## 第7章 贝叶斯分类器

### 7.1 贝叶斯决策论

### 7.2 极大似然估计

### 7.3 朴素贝叶斯分类器

### 7.4 半朴素贝叶斯分类器

### 7.5 贝叶斯网

### 7.6 EM算法

### 7.7 阅读材料

### 习题

### 参考文献

### 休息一会儿

## 第8章 集成学习

### 8.1 个体与集成

### 8.2 Boosting

### 8.3 Bagging与随机森林

### 8.4 结合策略

### 8.5 多样性

### 8.6 阅读材料

### 习题

### 参考文献

### 休息一会儿

## 第9章 聚类

### 9.1 聚类任务

### 9.2 性能度量

### 9.3 距离计算

### 9.4 原型聚类

### 9.5 密度聚类

### 9.6 层次聚类

### 9.7 阅读材料

### 习题

### 参考文献

### 休息一会儿

## 第10章 降维与度量学习

### 10.1 k近邻学习

### 10.2 低维嵌入

### 10.3 主成分分析

### 10.4 归纳偏好

### 10.5 流形学习

### 10.6 度量学习

### 10.7 阅读材料

### 习题

### 参考文献

### 休息一会儿

## 第11章 特征选择与稀疏学习

### 11.1 子集搜索与评价

### 11.2 过滤式选择

### 11.3 包裹式选择

### 11.4 嵌入式选择与L1正则化

### 11.5 稀疏表示与字典学习

### 11.6 压缩感知

### 11.7 阅读材料

### 习题

### 参考文献

### 休息一会儿

## 第12章 计算学习理论

### 12.1 基础知识

### 12.2 PAC学习

### 12.3 有限假设空间

### 12.4 VC维

### 12.5 Rademacher复杂度

### 12.6 稳定性

### 12.7 阅读材料

### 习题

### 参考文献

### 休息一会儿

## 第13章 半监督学习

### 13.1 未标记样本

### 13.2 生成式方法

### 13.3 半监督SVM

### 13.4 图半监督学习

### 13.5 基于分歧的方法

### 13.6 半监督聚类

### 13.7 阅读材料

### 习题

### 参考文献

### 休息一会儿

## 第14章 概率图模型

### 14.1 隐马尔可夫模型

### 14.2 马尔可夫随机场

### 14.3 条件随机场

### 14.4 学习与推断

### 14.5 近似推断

### 14.6 话题模型

### 14.7 阅读材料

### 习题

### 参考文献

### 休息一会儿

## 第15章 规则学习

### 15.1 基本概念

### 15.2 序贯覆盖

### 15.3 剪枝优化

### 15.4 一阶规则学习

### 15.5 归纳逻辑程序设计

### 15.6 阅读材料

### 习题

### 参考文献

### 休息一会儿

## 第16章 强化学习

### 16.1 任务与奖赏

### 16.2 K-摇臂赌博机

### 16.3 有模型学习

### 16.4 免模型学习

### 16.5 值函数近似

### 16.6 模仿学习

### 16.7 阅读材料

### 习题

### 参考文献

### 休息一会儿

## 附录

### A 矩阵

### B 优化

### C 概率分布

## 后记

